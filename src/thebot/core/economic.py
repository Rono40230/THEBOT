from .logger import logger
"""
Economic Calendar RSS Parser - Extension pour r√©cup√©rer les √©v√©nements √©conomiques
Sp√©cialis√© dans l'extraction d'√©v√©nements √©conomiques depuis les flux RSS
"""

import asyncio
import logging
import re
from datetime import datetime, timedelta, timezone
from typing import Any, Dict, List, Optional

import aiohttp
import feedparser
from bs4 import BeautifulSoup

logger = logging.getLogger(__name__)


class AsyncEconomicCalendarRSSParser:
    """Parser sp√©cialis√© pour les calendriers √©conomiques RSS - Version Async"""

    def __init__(self, timeout: int = 15, retries: int = 3):
        """
        Initialise le parser de calendrier √©conomique async

        Args:
            timeout: Timeout pour les requ√™tes HTTP
            retries: Nombre de tentatives en cas d'√©chec
        """
        self.timeout = timeout
        self.retries = retries
        self._session: Optional[aiohttp.ClientSession] = None

        # Sources RSS pour calendriers √©conomiques
        self.economic_rss_sources = [
            {
                "name": "Yahoo Finance Economics",
                "url": "https://feeds.finance.yahoo.com/rss/2.0/headline?s=^DJI,^GSPC,^IXIC&region=US&lang=en-US",
                "type": "yahoo_finance",
                "priority": 1,
            },
            {
                "name": "MarketWatch Real-time",
                "url": "https://feeds.marketwatch.com/marketwatch/realtimeheadlines/",
                "type": "marketwatch",
                "priority": 2,
            },
            {
                "name": "Investing.com General News",
                "url": "https://www.investing.com/rss/news.rss",
                "type": "investing_news",
                "priority": 3,
            },
            {
                "name": "Federal Reserve News",
                "url": "https://www.federalreserve.gov/feeds/press_all.xml",
                "type": "fed_news",
                "priority": 1,
            },
            {
                "name": "ECB Press Releases",
                "url": "https://www.ecb.europa.eu/rss/press.html",
                "type": "ecb_news",
                "priority": 1,
            },
        ]

        # Mapping des impacts par mots-cl√©s (am√©lior√© pour news g√©n√©rales)
        self.impact_keywords = {
            "critical": [
                "non-farm payroll",
                "nfp",
                "employment report",
                "jobs report",
                "fed rate",
                "federal reserve",
                "fomc",
                "interest rate decision",
                "ecb rate",
                "european central bank",
                "boe rate",
                "bank of england",
                "gdp report",
                "gross domestic product",
                "gdp growth",
                "cpi inflation",
                "consumer price index",
                "inflation report",
                "unemployment rate",
                "jobless claims",
            ],
            "high": [
                "retail sales",
                "consumer spending",
                "ism manufacturing",
                "ism services",
                "pmi",
                "purchasing managers index",
                "core cpi",
                "core inflation",
                "pce",
                "personal consumption expenditures",
                "housing starts",
                "durable goods",
                "factory orders",
                "trade balance",
                "current account",
            ],
            "medium": [
                "housing data",
                "existing home sales",
                "new home sales",
                "consumer confidence",
                "business sentiment",
                "consumer sentiment",
                "industrial production",
                "capacity utilization",
                "building permits",
                "pending home sales",
                "wholesale inventories",
            ],
            "low": [
                "leading indicators",
                "philadelphia fed",
                "empire state",
                "kansas city fed",
                "chicago pmi",
                "construction spending",
                "consumer credit",
                "import price index",
                "export price index",
            ],
        }

        # Pays et devises
        self.country_mapping = {
            "united states": "US",
            "usa": "US",
            "us": "US",
            "eurozone": "EU",
            "euro area": "EU",
            "eu": "EU",
            "united kingdom": "UK",
            "britain": "UK",
            "uk": "UK",
            "japan": "JP",
            "jp": "JP",
            "canada": "CA",
            "ca": "CA",
            "australia": "AU",
            "au": "AU",
            "switzerland": "CH",
            "ch": "CH",
            "china": "CN",
            "cn": "CN",
        }

    async def __aenter__(self):
        """Context manager entry - initialise la session aiohttp"""
        await self._ensure_session()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Context manager exit - ferme la session aiohttp"""
        await self._close_session()

    async def _ensure_session(self) -> None:
        """S'assure qu'une session aiohttp est disponible"""
        if self._session is None or self._session.closed:
            timeout = aiohttp.ClientTimeout(total=self.timeout)
            self._session = aiohttp.ClientSession(
                timeout=timeout,
                headers={
                    "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 THEBOT/1.0"
                }
            )
            logger.debug("üì° Session aiohttp initialis√©e pour economic parser")

    async def _close_session(self) -> None:
        """Ferme la session aiohttp"""
        if self._session and not self._session.closed:
            await self._session.close()
            logger.debug("üì° Session aiohttp ferm√©e pour economic parser")

    def get_economic_events(
        self, days_ahead: int = 7, max_events: int = 50
    ) -> List[Dict[str, Any]]:
        """
        R√©cup√®re les √©v√©nements √©conomiques des prochains jours

        Args:
            days_ahead: Nombre de jours √† l'avance
            max_events: Maximum d'√©v√©nements √† retourner

        Returns:
            Liste d'√©v√©nements √©conomiques normalis√©s
        """
        all_events = []

        for source in self.economic_rss_sources:
            try:
                events = self._parse_economic_rss(source, days_ahead)
                all_events.extend(events)
                logger.info(
                    f"‚úÖ {len(events)} √©v√©nements √©conomiques r√©cup√©r√©s depuis {source['name']}"
                )

                # Petit d√©lai entre les sources
                time.sleep(0.5)

            except Exception as e:
                logger.warning(f"‚ö†Ô∏è √âchec RSS {source['name']}: {e}")
                continue

        # D√©doublonnage et tri par date
        unique_events = self._deduplicate_events(all_events)
        unique_events.sort(key=lambda x: x.get("event_date", datetime.now()))

        logger.info(f"‚úÖ {len(unique_events)} √©v√©nements √©conomiques uniques r√©cup√©r√©s")
        return unique_events[:max_events]

    async def get_economic_events_async(
        self, days_ahead: int = 7, max_events: int = 50
    ) -> List[Dict[str, Any]]:
        """
        R√©cup√®re les √©v√©nements √©conomiques des prochains jours - Version Async

        Args:
            days_ahead: Nombre de jours √† l'avance
            max_events: Maximum d'√©v√©nements √† retourner

        Returns:
            Liste d'√©v√©nements √©conomiques normalis√©s
        """
        all_events = []

        for source in self.economic_rss_sources:
            try:
                events = await self._parse_economic_rss_async(source, days_ahead)
                all_events.extend(events)
                logger.info(
                    f"‚úÖ {len(events)} √©v√©nements √©conomiques r√©cup√©r√©s depuis {source['name']}"
                )

                # Petit d√©lai entre les sources
                await asyncio.sleep(0.5)

            except Exception as e:
                logger.warning(f"‚ö†Ô∏è √âchec RSS {source['name']}: {e}")
                continue

        # D√©doublonnage et tri par date
        unique_events = self._deduplicate_events(all_events)
        unique_events.sort(key=lambda x: x.get("event_date", datetime.now()))

        logger.info(f"‚úÖ {len(unique_events)} √©v√©nements √©conomiques uniques r√©cup√©r√©s")
        return unique_events[:max_events]

    def _parse_economic_rss(
        self, source: Dict, days_ahead: int
    ) -> List[Dict[str, Any]]:
        """Parse un flux RSS sp√©cifique de calendrier √©conomique"""

        try:
            # R√©cup√©ration du contenu RSS
            response = self.session.get(source["url"], timeout=self.timeout)
            response.raise_for_status()

            # Parse du flux RSS
            feed = feedparser.parse(response.content)

            if not feed.entries:
                logger.warning(f"‚ö†Ô∏è Aucune entr√©e dans le flux RSS {source['name']}")
                return []

            events = []
            target_date = datetime.now() + timedelta(days=days_ahead)

            for entry in feed.entries:
                try:
                    # Extraction des donn√©es de base
                    event = self._extract_event_data(entry, source)

                    # Filtrer seulement les vraies nouvelles √©conomiques
                    if self._is_economic_event(event):
                        # Pour les actualit√©s r√©centes, on les garde toutes (moins de filtrage par date)
                        event_date = event.get("event_date")
                        if not event_date:
                            events.append(event)
                        else:
                            # G√©rer les comparaisons de dates avec/sans timezone
                            try:
                                # Assurer que les deux dates ont la m√™me timezone
                                now = datetime.now()
                                if event_date.tzinfo is not None and now.tzinfo is None:
                                    now = now.replace(tzinfo=timezone.utc)
                                elif (
                                    event_date.tzinfo is None and now.tzinfo is not None
                                ):
                                    event_date = event_date.replace(tzinfo=timezone.utc)

                                if event_date >= now - timedelta(days=2):
                                    events.append(event)
                            except:
                                # En cas d'erreur, on garde l'√©v√©nement
                                events.append(event)

                except Exception as e:
                    logger.debug(f"√âchec parsing entr√©e RSS: {e}")
                    continue

            return events

        except Exception as e:
            logger.error(f"‚ùå Erreur parsing RSS {source['name']}: {e}")
            return []

    async def _parse_economic_rss_async(
        self, source: Dict, days_ahead: int
    ) -> List[Dict[str, Any]]:
        """Parse un flux RSS sp√©cifique de calendrier √©conomique - Version Async"""

        try:
            await self._ensure_session()

            # R√©cup√©ration du contenu RSS
            async with self._session.get(source["url"]) as response:
                response.raise_for_status()
                content = await response.read()

            # Parse du flux RSS
            feed = feedparser.parse(content)

            if not feed.entries:
                logger.warning(f"‚ö†Ô∏è Aucune entr√©e dans le flux RSS {source['name']}")
                return []

            events = []
            target_date = datetime.now() + timedelta(days=days_ahead)

            for entry in feed.entries:
                try:
                    # Extraction des donn√©es de base
                    event = self._extract_event_data(entry, source)

                    # Filtrer seulement les vraies nouvelles √©conomiques
                    if self._is_economic_event(event):
                        # Pour les actualit√©s r√©centes, on les garde toutes (moins de filtrage par date)
                        event_date = event.get("event_date")
                        if not event_date:
                            events.append(event)
                        else:
                            # G√©rer les comparaisons de dates avec/sans timezone
                            try:
                                # Assurer que les deux dates ont la m√™me timezone
                                now = datetime.now()
                                if event_date.tzinfo is not None and now.tzinfo is None:
                                    now = now.replace(tzinfo=timezone.utc)
                                elif (
                                    event_date.tzinfo is None and now.tzinfo is not None
                                ):
                                    event_date = event_date.replace(tzinfo=timezone.utc)

                                if event_date >= now - timedelta(days=2):
                                    events.append(event)
                            except:
                                # En cas d'erreur, on garde l'√©v√©nement
                                events.append(event)

                except Exception as e:
                    logger.debug(f"√âchec parsing entr√©e RSS: {e}")
                    continue

            return events

        except Exception as e:
            logger.error(f"‚ùå Erreur parsing RSS {source['name']}: {e}")
            return []

    def _extract_event_data(self, entry: Any, source: Dict) -> Dict[str, Any]:

        # D√©tection de l'impact
        impact = self._detect_impact(title, description)

        # Extraction d'autres donn√©es
        event_data = {
            "id": f"{source['type']}_{hash(title + str(event_date))}",
            "title": title,
            "description": description[:500] if description else title,
            "country": country,
            "impact": impact,
            "event_date": event_date,
            "event_time": event_date.strftime("%H:%M") if event_date else "TBD",
            "source": source["name"],
            "source_url": entry.get("link", source["url"]),
            "category": self._categorize_event(title, description),
            "currency": self._get_currency_from_country(country),
            "previous_value": None,  # Sera extrait si disponible
            "forecast_value": None,  # Sera extrait si disponible
            "actual_value": None,  # Sera mis √† jour apr√®s publication
            "is_released": self._safe_datetime_compare(event_date),
            "scraped_at": datetime.now(),
        }

        # Extraction des valeurs num√©riques si disponibles
        self._extract_numerical_values(event_data, description)

        return event_data

    def _extract_event_date(self, entry: Any) -> Optional[datetime]:
        """Extrait la date de l'√©v√©nement depuis l'entr√©e RSS"""

        # Essayer plusieurs champs de date
        date_fields = ["published_parsed", "updated_parsed", "created_parsed"]

        for field in date_fields:
            if hasattr(entry, field) and getattr(entry, field):
                try:
                    time_struct = getattr(entry, field)
                    return datetime(*time_struct[:6], tzinfo=timezone.utc)
                except:
                    continue

        # Extraction depuis le titre ou description
        title_desc = f"{entry.get('title', '')} {entry.get('summary', '')}"

        # Patterns de date courantes
        date_patterns = [
            r"(\d{1,2}[/-]\d{1,2}[/-]\d{4})",  # DD/MM/YYYY ou MM/DD/YYYY
            r"(\d{4}[/-]\d{1,2}[/-]\d{1,2})",  # YYYY/MM/DD
            r"(today|tomorrow|yesterday)",  # Mots-cl√©s temporels
        ]

        for pattern in date_patterns:
            match = re.search(pattern, title_desc.lower())
            if match:
                try:
                    date_str = match.group(1)
                    if date_str == "today":
                        return datetime.now()
                    elif date_str == "tomorrow":
                        return datetime.now() + timedelta(days=1)
                    elif date_str == "yesterday":
                        return datetime.now() - timedelta(days=1)
                    else:
                        # Tentative de parsing de date
                        for fmt in [
                            "%d/%m/%Y",
                            "%m/%d/%Y",
                            "%Y/%m/%d",
                            "%d-%m-%Y",
                            "%Y-%m-%d",
                        ]:
                            try:
                                return datetime.strptime(date_str, fmt)
                            except:
                                continue
                except:
                    continue

        # Par d√©faut, utiliser la date actuelle
        return datetime.now()

    def _detect_country(self, title: str, description: str) -> str:
        """D√©tecte le pays de l'√©v√©nement √©conomique"""

        text = f"{title} {description}".lower()

        for country_name, code in self.country_mapping.items():
            if country_name in text:
                return code

        # D√©tection par devise
        if any(currency in text for currency in ["usd", "dollar", "fed", "fomc"]):
            return "US"
        elif any(currency in text for currency in ["eur", "euro", "ecb"]):
            return "EU"
        elif any(currency in text for currency in ["gbp", "pound", "boe"]):
            return "UK"
        elif any(currency in text for currency in ["jpy", "yen", "boj"]):
            return "JP"

        return "US"  # Par d√©faut

    def _detect_impact(self, title: str, description: str) -> str:
        """D√©tecte le niveau d'impact de l'√©v√©nement"""

        text = f"{title} {description}".lower()

        for impact_level, keywords in self.impact_keywords.items():
            for keyword in keywords:
                if keyword in text:
                    return impact_level

        return "medium"  # Par d√©faut

    def _categorize_event(self, title: str, description: str) -> str:
        """Cat√©gorise l'√©v√©nement √©conomique"""

        text = f"{title} {description}".lower()

        if any(
            word in text
            for word in ["employment", "unemployment", "jobs", "payroll", "jobless"]
        ):
            return "employment"
        elif any(
            word in text for word in ["rate", "fed", "ecb", "boe", "monetary", "policy"]
        ):
            return "monetary_policy"
        elif any(word in text for word in ["inflation", "cpi", "pce", "price"]):
            return "inflation"
        elif any(word in text for word in ["gdp", "growth", "economic", "activity"]):
            return "economic_activity"
        elif any(word in text for word in ["retail", "sales", "consumer", "spending"]):
            return "consumption"
        else:
            return "other"

    def _get_currency_from_country(self, country: str) -> str:
        """Retourne la devise principale du pays"""

        currency_map = {
            "US": "USD",
            "EU": "EUR",
            "UK": "GBP",
            "JP": "JPY",
            "CA": "CAD",
            "AU": "AUD",
            "CH": "CHF",
            "CN": "CNY",
        }

        return currency_map.get(country, "USD")

    def _safe_datetime_compare(self, event_date: Optional[datetime]) -> bool:
        """Compare des dates avec gestion s√©curis√©e des timezones"""
        if not event_date:
            return False

        try:
            now = datetime.now()

            # Assurer que les deux dates ont la m√™me timezone
            if event_date.tzinfo is not None and now.tzinfo is None:
                now = now.replace(tzinfo=timezone.utc)
            elif event_date.tzinfo is None and now.tzinfo is not None:
                event_date = event_date.replace(tzinfo=timezone.utc)

            return event_date < now
        except:
            # En cas d'erreur, consid√©rer comme non publi√©
            return False

    def _extract_numerical_values(self, event_data: Dict, description: str):
        """Extrait les valeurs num√©riques (pr√©vu, pr√©c√©dent, actuel)"""

        # Patterns pour extraire les valeurs
        patterns = {
            "previous": r"previous:?\s*([+-]?\d+\.?\d*[%]?)",
            "forecast": r"forecast:?\s*([+-]?\d+\.?\d*[%]?)",
            "expected": r"expected:?\s*([+-]?\d+\.?\d*[%]?)",
            "actual": r"actual:?\s*([+-]?\d+\.?\d*[%]?)",
        }

        for field, pattern in patterns.items():
            match = re.search(pattern, description.lower())
            if match:
                value = match.group(1)
                if field == "previous":
                    event_data["previous_value"] = value
                elif field in ["forecast", "expected"]:
                    event_data["forecast_value"] = value
                elif field == "actual":
                    event_data["actual_value"] = value

    def _deduplicate_events(self, events: List[Dict]) -> List[Dict]:
        """Supprime les √©v√©nements en double"""

        seen = set()
        unique_events = []

        for event in events:
            # Cl√© unique bas√©e sur titre + date + pays
            key = f"{event['title']}_{event.get('event_date', '')}_{event['country']}"

            if key not in seen:
                seen.add(key)
                unique_events.append(event)

        return unique_events

    def _is_economic_event(self, event: Dict) -> bool:
        """D√©termine si un article est un vrai √©v√©nement √©conomique (version permissive)"""

        title = event.get("title", "").lower()
        description = event.get("description", "").lower()
        text = f"{title} {description}"

        # Mots-cl√©s √©conomiques principaux (plus permissif)
        economic_keywords = [
            "fed",
            "federal reserve",
            "ecb",
            "european central bank",
            "boe",
            "bank of england",
            "inflation",
            "cpi",
            "pce",
            "gdp",
            "employment",
            "unemployment",
            "jobs",
            "retail sales",
            "housing",
            "manufacturing",
            "pmi",
            "ism",
            "rate",
            "monetary",
            "policy",
            "economy",
            "economic",
            "market",
            "stocks",
            "trading",
            "financial",
            "finance",
        ]

        # V√©rifier pr√©sence de mots-cl√©s √©conomiques
        has_economic = any(keyword in text for keyword in economic_keywords)

        # Mots-cl√©s d'exclusion (r√©duite)
        exclude_keywords = [
            "crypto",
            "bitcoin",
            "ethereum",  # Seulement crypto pour √©viter duplication
        ]

        has_exclude = any(keyword in text for keyword in exclude_keywords)

        return has_economic and not has_exclude


# Instance globale - Version Async
async def get_economic_calendar_parser() -> AsyncEconomicCalendarRSSParser:
    """Factory function pour obtenir une instance AsyncEconomicCalendarRSSParser"""
    return AsyncEconomicCalendarRSSParser()

# Classe legacy pour compatibilit√© - √Ä migrer vers AsyncEconomicCalendarRSSParser
class EconomicCalendarRSSParser:
    """
    ‚ö†Ô∏è DEPRECATED: Utilisez AsyncEconomicCalendarRSSParser √† la place

    Version synchrone conserv√©e pour compatibilit√© temporaire.
    Sera supprim√©e dans une future version.
    """

    def __init__(self, timeout: int = 15, retries: int = 3):
        import warnings
        warnings.warn(
            "EconomicCalendarRSSParser is deprecated. Use AsyncEconomicCalendarRSSParser instead.",
            DeprecationWarning,
            stacklevel=2
        )
        self.timeout = timeout
        self.retries = retries

    def get_economic_events(self, days_ahead: int = 7, max_events: int = 50) -> List[Dict[str, Any]]:
        """‚ö†Ô∏è DEPRECATED: Utilisez AsyncEconomicCalendarRSSParser.get_economic_events_async()"""
        raise NotImplementedError("Use AsyncEconomicCalendarRSSParser for async operations")
